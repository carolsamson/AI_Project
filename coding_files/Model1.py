# -*- coding: utf-8 -*-
"""Nasdaq_Prediction_30_days_72_ts_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1caliZ25J38kJmkKOl9VY-jA3TcLiPW3X

### Stock Market Prediction And Forecasting Using Stacked LSTM
"""

import numpy as np
import pandas as pd
import yfinance as yf
import os
import ta
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional
import matplotlib.pyplot as plt
from keras.callbacks import EarlyStopping
from sklearn.decomposition import PCA
from sklearn.model_selection import TimeSeriesSplit

"""### Data Loading & Preprocessing"""

# Load the dataset
file_path = 'nasdaq.csv'
nasdaq_data = pd.read_csv(file_path)

nasdaq_data.head()

nasdaq_data.tail()

# Add moving averages
nasdaq_data['MA10'] = nasdaq_data['Close'].rolling(window=10).mean()
nasdaq_data['MA50'] = nasdaq_data['Close'].rolling(window=10).mean()
nasdaq_data['MA200'] = nasdaq_data['Close'].rolling(window=10).mean()

nasdaq_data.dropna(inplace=True)  # Drop rows with NaN values

# Drop the unnecessary columns
df = nasdaq_data.drop(columns=['Unnamed: 0', 'Date', 'Volume', 'Open', 'High',	'Low'	])

df.head(15)

# Use all columns except 'Close' as features for X
features = df.columns.tolist()
# features = ['EMA_50', 'EMA_200', 'RSI', 'MACD', 'MACD_Signal', 'MACD_Hist']
features.remove('Close')

# Prepare X and Y
X = df[features].values
Y = df['Close'].values

### LSTM are sensitive to the scale of the data. so we apply MinMax scaler
# Normalize the dataset
scaler_X = MinMaxScaler(feature_range=(0, 1))
scaler_Y = MinMaxScaler(feature_range=(0, 1))

X_scaled = scaler_X.fit_transform(X)
Y_scaled = scaler_Y.fit_transform(Y.reshape(-1, 1))

# Create sequences (lookback period)
lookback = 120
X_seq = []
Y_seq = []

for i in range(lookback, len(X_scaled)):
    X_seq.append(X_scaled[i-lookback:i])
    Y_seq.append(Y_scaled[i])

X_seq, Y_seq = np.array(X_seq), np.array(Y_seq)

# TimeSeriesSplit for train-test split
tscv = TimeSeriesSplit(n_splits=10)
for train_index, test_index in tscv.split(X_seq):
    X_train, X_test = X_seq[train_index], X_seq[test_index]
    Y_train, Y_test = Y_seq[train_index], Y_seq[test_index]

"""### Model: Stacked LSTM for price prediction"""

from keras.regularizers import l2
# Define the LSTM model
# model = Sequential()
# model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
# model.add(Dropout(0.2))
# model.add(LSTM(units=50, return_sequences=False))
# model.add(Dropout(0.2))
# model.add(Dense(units=1))  # Predicting the 'Close' price

# Define the LSTM model with L2 regularization applied to all layers
model = Sequential()
model.add(LSTM(units=100, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2]), kernel_regularizer=l2(0.000001)))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=False, kernel_regularizer=l2(0.000001)))
model.add(Dropout(0.2))
model.add(Dense(units=1, kernel_regularizer=l2(0.000001)))  # Predicting the 'Close' price

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the model
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
history = model.fit(X_train, Y_train, epochs=100, batch_size=32, validation_data=(X_test, Y_test), verbose=1, callbacks=[early_stopping])

# Evaluate the model
loss = model.evaluate(X_test, Y_test, verbose=1)
print(f'Test Loss: {loss}')

# Plotting training & validation loss values
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss over Epochs')
plt.legend()
plt.grid(True)
plt.show()

import seaborn as sns
# Calculate the correlation matrix
correlation_matrix = df.corr()

# Plot the heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, fmt=".2f")
plt.title('Correlation Matrix of NASDAQ Features')
plt.show()

X_train.shape[1], X_train.shape[2]

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Make predictions
Y_pred_scaled = model.predict(X_test)

# Inverse transform the predictions and actual values
Y_pred = scaler_Y.inverse_transform(Y_pred_scaled)
Y_actual = scaler_Y.inverse_transform(Y_test)

# Calculate MSE and RMSE
mse = mean_squared_error(Y_actual, Y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(Y_actual, Y_pred)
r2 = r2_score(Y_actual,Y_pred)

print(f'MSE: {mse}')
print(f'RMSE: {rmse}')
print(f'MAE: {mae}')
print(f'R2 Score: {r2}')

# Define a threshold for a prediction to be considered 'true'
threshold = 0.02  # for example, 2%

# Calculate the absolute percent error for each prediction
errors = np.abs((Y_pred - Y_actual) / Y_actual)

# Count the number of 'true' predictions
num_true_predictions = np.sum(errors < threshold)

# Calculate the accuracy
accuracy = num_true_predictions / len(Y_pred)

print(f'Accuracy: {accuracy}')

# Generate predictions for the next 30 days
future_predictions = []
last_sequence = X_scaled[-lookback:]

for _ in range(30):
    # Make prediction
    next_prediction_scaled = model.predict(last_sequence.reshape(1, lookback, -1))
    next_prediction = scaler_Y.inverse_transform(next_prediction_scaled)
    future_predictions.append(next_prediction[0][0])

    # Update the sequence by appending the prediction and removing the oldest entry
    next_prediction_features = np.append(last_sequence[-1, :-1], next_prediction_scaled).reshape(1, -1)
    last_sequence = np.append(last_sequence[1:], next_prediction_features, axis=0)

# Prepare dates for plotting future predictions
last_date = pd.to_datetime(nasdaq_data['Date'].iloc[-1])
future_dates = [last_date + pd.DateOffset(days=i) for i in range(1, 31)]

# Print next 30 days prices with dates
for date, price in zip(future_dates, future_predictions):
    print(f'Date: {date}, Predicted Close Price: {price}')

Y_actual.shape, Y_pred.shape

"""### Visualizations"""

full_dates = pd.to_datetime(nasdaq_data['Date'])

# Plot actual and predicted values
plt.figure(figsize=(14, 7))

# Subplot 1: Actual values
plt.subplot(2, 1, 1)
plt.plot(full_dates[-len(Y_actual):], Y_actual, color='blue', label='Actual NASDAQ Price')
plt.title('Actual NASDAQ Price')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.xticks(rotation=45)

# Subplot 2: Predicted values
plt.subplot(2, 1, 2)
plt.plot(full_dates[-len(Y_pred):], Y_pred, color='red', label='Predicted NASDAQ Price')
plt.title('Predicted NASDAQ Price')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

# Create a figure
plt.figure(figsize=(14, 7))

# Plot actual values
plt.plot(full_dates[-len(Y_actual):], Y_actual, color='blue', label='Actual NASDAQ Price')

# Plot predicted values
plt.plot(full_dates[-len(Y_pred):], Y_pred, color='red', label='Predicted NASDAQ Price')

# Set title, labels and legend
plt.title('NASDAQ Price: Actual vs Predicted')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()

# Rotate x-axis labels
plt.xticks(rotation=45)

# Show the plot
plt.tight_layout()
plt.show()

# Plot actual and predicted values
plt.figure(figsize=(14, 7))
plt.plot(full_dates[-len(Y_scaled):], scaler_Y.inverse_transform(Y_scaled).flatten(), color='green', label='Actual NASDAQ Price')
plt.plot(future_dates, future_predictions, color='red', label='Predicted NASDAQ Price (Next 30 Days)')
plt.title('NASDAQ Price Prediction')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Calculate the number of trading days in a year (usually around 252)
trading_days_in_a_year = 252

# Select the data for the last one year
last_year_dates = full_dates[-trading_days_in_a_year:]
last_year_prices = scaler_Y.inverse_transform(Y_scaled[-trading_days_in_a_year:]).flatten()

# Plot actual and predicted values
plt.figure(figsize=(14, 7))
plt.plot(last_year_dates, last_year_prices, color='green', label='Actual NASDAQ Price')
plt.plot(future_dates, future_predictions, color='red', label='Predicted NASDAQ Price (Next 30 Days)')
plt.title('NASDAQ Price Prediction')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""### Model Interpretability using LIME"""

import lime
from lime.lime_tabular import LimeTabularExplainer
import numpy as np

# LIME for model interpretability
explainer = LimeTabularExplainer(
    training_data=X_train.reshape(X_train.shape[0], -1),
    feature_names=features * lookback,
    class_names=['Close'],
    mode='regression'
)

# Choose an instance to explain (e.g., the first instance in the test set)
instance_idx = 0
instance = X_test[instance_idx].reshape(1, X_test.shape[1], X_test.shape[2])

# Get the predicted value for the instance
predicted_value_scaled = model.predict(instance).flatten()[0]

# Inverse transform the predicted value to get it back to the original scale
predicted_value_original_scale = scaler_Y.inverse_transform([[predicted_value_scaled]])[0][0]

# Get the actual value for the instance
actual_value_scaled = Y_test[instance_idx].reshape(1, -1)  # Reshape to 2D array
actual_value_original_scale = scaler_Y.inverse_transform(actual_value_scaled)[0][0]

# Print the predicted and actual values
print(f'Original value for the instance: {actual_value_original_scale}')
print(f'Predicted value for the instance: {predicted_value_original_scale}')

print(f'Predicted value for the instance (scaled): {predicted_value_scaled}')


# Explain the instance
exp = explainer.explain_instance(
    data_row=instance.flatten(),
    predict_fn=lambda x: model.predict(x.reshape(-1, X_test.shape[1], X_test.shape[2])).flatten(),
    num_features=len(features)  # Include all features in the explanation
)

# Explain the instance
exp = explainer.explain_instance(
    data_row=instance.flatten(),
    predict_fn=lambda x: model.predict(x.reshape(-1, X_test.shape[1], X_test.shape[2])).flatten(),
    num_features=len(features)  # Include all features in the explanation
)

# Show the explanation
exp.show_in_notebook(show_table=True)